## Архитектура Spark

Приложения, которые создаются на базе фреймворка Spark, предназначены для работы в распределенной среде (например, в кластере, состоящем из нескольких узлов). **Архитектура распределенной (параллельной) среды включает в себя следующие компоненты**:

* драйвер Spark
* Spark-исполнители

![Avatar](https://sun9-west.userapi.com/sun9-63/s/v1/ig2/JWj3Z4hMohxWsB5m1qbcPvSID2j2CltG3mxapK_frMOlErRtoQtZLuI4kSSEXWAqNCwra13Mhvuq_vD6tNk6YfRL.jpg?size=625x704&quality=96&type=album)

### Драйвер  спарк
**Драйвер Spark – это процесс, который распределяет задачи, поступающие от пользователя по действующим исполнителям**. Таким образом, Spark-драйвер **преобразует пользовательское приложение на единицы исполнения**, которые называются задачи (tasks). **Экземпляр Spark-драйвера** запускается во время запуска сессии (драйвер Spark создает сессию) Spark при первом запуске приложения и остается активным до тех пор, эта сессия активна (приложение работает и сбой не произошел).
Приложение может разбиваться на несколько сотен и даже тысяч заданий (в зависимости от функционала). На основе составленного плана со всеми задачами **драйвер Spark контролирует передачу этих задач исполнителям**. При запуске каждый исполнитель регистрирует себя в драйвере.

### Спарк исполнители
**Spark-исполнители (Spark executors) – это рабочие процессы, которые отвечают за выполнение задач, приходящих из драйвера**. Исполнители запускаются только один раз при запуске приложения Spark и продолжают свою работу на протяжении всего жизненного цикла программы. **Они выполняют задачи, приходящие от драйвера и возвращают результат обратно драйверу Spark**. Каждому исполнителю, также, как и драйверу выделяется определенный объем оперативной памяти, значение которого по умолчанию составляет 1Гб. Каждый исполнитель имеет определенное число ядер (cores). Ядро исполнителя (executor core) отвечает за параллельное выполнение задач одним исполнителем

![Avatar](https://sun9-west.userapi.com/sun9-46/s/v1/ig2/RvEKNHggie9kmFVjLXdptCggFMxglitPzyCKwD-DY_beL5La_bQceXMxVhnEjzMxq46q-nZeJLyjXAeqwK1tSxhH.jpg?size=974x467&quality=96&type=album)

Чем больше количество ядер, тем больше задач может одновременно выполнять один исполнитель. Однако стоит контролировать количество ядер в каждом исполнителе, так как каждое ядро требует значительных затрат мощности процессора. Слишком большое количество ядер может привести к сбою приложения. 
Таким образом, распределенная **архитектура приложения Spark позволяет выполнять большие объемы Big Data задач, требующих высокое количество вычислений**. Все это делает framework Apache Spark весьма полезным средством для Data Scientist’а и разработчика Big Data приложений. 

---

### Исполнитель
**Исполнитель (Executor) – распределённый процесс, который отвечает за выполнение задач**. У каждого приложения Spark собственный набор исполнителей. Они работают в течение жизненного цикла отдельного приложения Spark.

* Исполнители делают всю обработку данных задания Spark
* Сохраняют результаты в памяти, а на диске – только тогда, когда это специально указывается в программе-драйвере (Driver Program).
* Возвращает результаты драйверу после их завершения.
*	Каждый узел может иметь от 1 исполнителя на узел до 1 исполнителя на ядро.

![Avatar](https://sun9-north.userapi.com/sun9-77/s/v1/ig2/asPWACs2Y8IwN5_YrsjrI6elFYprzRXym-SiMemEN6PuAKClwCZX0XNQ32-QQd_Na-bYfIeD1yrSUVLvr_CW8nT_.jpg?size=974x423&quality=96&type=album)

---
### Список используемых источников:

1. [What Is Apache Spark?: YouTube](https://www.youtube.com/watch?v=znBa13Earms&t=1873s)
2. [What is the Spark Distributed Environment architecture?](https://spark-school.ru/blogs/spark-parallel-architecture/)
3. [Spark framework: proglib](https://proglib.io/p/spark-overview)


                     Щепетова Татьяна, 19-ПМ-2